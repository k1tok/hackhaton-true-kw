{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzcCrAxK_9Xb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_engineered_features(df):\n",
        "    # Расчёт total_consumption\n",
        "    consumption_cols = [f'consumption_{i}' for i in range(1, 13)]\n",
        "    df['total_consumption'] = df[consumption_cols].sum(axis=1)\n",
        "    df['mean_consumption'] = df[consumption_cols].mean(axis=1)\n",
        "    df['std_consumption'] = df[consumption_cols].std(axis=1)\n",
        "    df['max_consumption'] = df[consumption_cols].max(axis=1)\n",
        "    df['min_consumption'] = df[consumption_cols].min(axis=1)\n",
        "\n",
        "    # Ежемесячные дельты (разница между месяцами)\n",
        "    deltas = []\n",
        "    for i in range(2, 13):\n",
        "        deltas.append(df[f'consumption_{i}'] - df[f'consumption_{i-1}'])\n",
        "    df['monthly_delta'] = pd.concat(deltas, axis=1).abs().mean(axis=1)\n",
        "\n",
        "    # Потребление на жителя и на комнату (с учетом типа здания)\n",
        "    df['cons_per_resident'] = df['total_consumption'] / df['residentsCount'].replace(0, 1)\n",
        "    df['cons_per_room'] = df['total_consumption'] / df['roomsCount'].replace(0, 1)\n",
        "\n",
        "    # Коэффициент сезонности — std / mean потребления\n",
        "    df['seasonality_coef'] = df['std_consumption'] / (df['mean_consumption'] + 1e-6)\n",
        "\n",
        "    # Масштаб потребления с учетом типа здания\n",
        "    # Допустим, для \"Многоквартирный\" — делим на 1, для \"Частный\" — на 0.8, \"Прочий\" — на 0.9 (пример)\n",
        "    scale_map = {'Многоквартирный': 1.0, 'Частный': 0.8, 'Прочий': 0.9}\n",
        "    df['building_scale'] = df['buildingType'].map(scale_map).fillna(1.0)\n",
        "    df['scaled_cons_per_resident'] = df['cons_per_resident'] * df['building_scale']\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def remove_outliers(df):\n",
        "    # Удалим выбросы по total_consumption (например, 1% и 99% квантиль)\n",
        "    lower_bound = df['total_consumption'].quantile(0.01)\n",
        "    upper_bound = df['total_consumption'].quantile(0.99)\n",
        "    before = len(df)\n",
        "    df = df[(df['total_consumption'] >= lower_bound) & (df['total_consumption'] <= upper_bound)]\n",
        "    after = len(df)\n",
        "    logging.info(f'Outliers removed: {before - after}')\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "l25he1a_ABgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_consumption(consumption_dict):\n",
        "    # Если consumption - словарь с месяцами, возвращаем список из 12 элементов\n",
        "    result = []\n",
        "    for month in range(1, 13):\n",
        "        val = consumption_dict.get(str(month), np.nan) if isinstance(consumption_dict, dict) else np.nan\n",
        "        result.append(val)\n",
        "    return result\n",
        "\n",
        "def load_and_preprocess(json_path):\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        raw_data = json.load(f)\n",
        "\n",
        "    records = []\n",
        "    for entry in raw_data:\n",
        "        flat = {\n",
        "            \"accountId\": entry.get(\"accountId\"),\n",
        "            \"roomsCount\": entry.get(\"roomsCount\", np.nan),\n",
        "            \"residentsCount\": entry.get(\"residentsCount\", 0),\n",
        "            \"buildingType\": entry.get(\"buildingType\", \"Прочий\"),\n",
        "            \"isCommercial\": entry.get(\"isCommercial\")  # <-- добавляем метку класса\n",
        "        }\n",
        "        consumption_values = flatten_consumption(entry.get(\"consumption\", {}))\n",
        "        for i, val in enumerate(consumption_values, 1):\n",
        "            flat[f\"consumption_{i}\"] = val\n",
        "        records.append(flat)\n",
        "\n",
        "    df = pd.DataFrame(records)\n",
        "    df = add_engineered_features(df)\n",
        "    df = remove_outliers(df)\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "uiYvLbGzANSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.head())\n",
        "print(df_train.columns)\n",
        "print(df_train['isCommercial'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHykwlTUBu-8",
        "outputId": "962ec9ad-a37a-4c09-c1d4-408bf501ec10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   accountId  roomsCount  residentsCount buildingType  isCommercial  \\\n",
            "0       1497         1.0               1      Частный          True   \n",
            "1       1509         1.0               1      Частный          True   \n",
            "2       1674         3.0               2      Частный          True   \n",
            "3       1955         5.0               1      Частный          True   \n",
            "4       1960         3.0               3      Частный          True   \n",
            "\n",
            "   consumption_1  consumption_2  consumption_3  consumption_4  consumption_5  \\\n",
            "0         3484.0         2824.0         3035.0         3597.0         2664.0   \n",
            "1         3756.0         1580.0         3191.0         2931.0          793.0   \n",
            "2         1543.0         1075.0         2344.0         1125.0         1045.0   \n",
            "3         5564.0         6201.0         5364.0         4031.0         5452.0   \n",
            "4          631.0          616.0          439.0          562.0         4723.0   \n",
            "\n",
            "   ...  mean_consumption  std_consumption  max_consumption  min_consumption  \\\n",
            "0  ...       3142.166667       474.448931           3874.0           2216.0   \n",
            "1  ...       1556.833333      1195.472887           3756.0            426.0   \n",
            "2  ...       1399.000000       429.457163           2344.0            914.0   \n",
            "3  ...       4587.375000      1777.585356           6201.0            590.0   \n",
            "4  ...       5869.583333      6997.939482          20134.0            439.0   \n",
            "\n",
            "   monthly_delta  cons_per_resident  cons_per_room  seasonality_coef  \\\n",
            "0     556.545455       37706.000000   37706.000000          0.150994   \n",
            "1     773.000000       18682.000000   18682.000000          0.767888   \n",
            "2     502.545455        8394.000000    5596.000000          0.306974   \n",
            "3    1507.666667       36699.000000    7339.800000          0.387495   \n",
            "4    3572.272727       23478.333333   23478.333333          1.192238   \n",
            "\n",
            "   building_scale  scaled_cons_per_resident  \n",
            "0             0.8              30164.800000  \n",
            "1             0.8              14945.600000  \n",
            "2             0.8               6715.200000  \n",
            "3             0.8              29359.200000  \n",
            "4             0.8              18782.666667  \n",
            "\n",
            "[5 rows x 28 columns]\n",
            "Index(['accountId', 'roomsCount', 'residentsCount', 'buildingType',\n",
            "       'isCommercial', 'consumption_1', 'consumption_2', 'consumption_3',\n",
            "       'consumption_4', 'consumption_5', 'consumption_6', 'consumption_7',\n",
            "       'consumption_8', 'consumption_9', 'consumption_10', 'consumption_11',\n",
            "       'consumption_12', 'total_consumption', 'mean_consumption',\n",
            "       'std_consumption', 'max_consumption', 'min_consumption',\n",
            "       'monthly_delta', 'cons_per_resident', 'cons_per_room',\n",
            "       'seasonality_coef', 'building_scale', 'scaled_cons_per_resident'],\n",
            "      dtype='object')\n",
            "isCommercial\n",
            "False    2877\n",
            "True     1851\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_preprocessor():\n",
        "    numeric_features = ['roomsCount', 'residentsCount'] + [f'consumption_{i}' for i in range(1, 13)] + [\n",
        "        'total_consumption', 'mean_consumption', 'std_consumption', 'max_consumption', 'min_consumption',\n",
        "        'monthly_delta', 'cons_per_resident', 'cons_per_room', 'seasonality_coef', 'scaled_cons_per_resident'\n",
        "    ]\n",
        "    categorical_features = ['buildingType']\n",
        "\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ]\n",
        "    )\n",
        "    return preprocessor\n",
        "\n",
        "\n",
        "def prepare_train_data(df, target_column='isCommercial'):\n",
        "    X = df.drop(columns=['accountId', target_column])\n",
        "    y = df[target_column].values\n",
        "    preprocessor = create_preprocessor()\n",
        "    X_proc = preprocessor.fit_transform(X)\n",
        "    return X_proc, y, preprocessor\n"
      ],
      "metadata": {
        "id": "sxn8ijlaAWTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_keras_model(input_dim):\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(X, y):\n",
        "    # Балансировка классов с SMOTE\n",
        "    sm = SMOTE(random_state=42)\n",
        "    X_res, y_res = sm.fit_resample(X, y)\n",
        "    logging.info(f\"Original dataset shape: {np.bincount(y)}\")\n",
        "    logging.info(f\"Resampled dataset shape: {np.bincount(y_res)}\")\n",
        "\n",
        "    # class_weight (на всякий случай)\n",
        "    from sklearn.utils import class_weight\n",
        "    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_res), y=y_res)\n",
        "    class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    # Делим на train/val\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = build_keras_model(X.shape[1])\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    start = time.time()\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        class_weight=class_weights_dict,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=2\n",
        "    )\n",
        "    end = time.time()\n",
        "    logging.info(f\"Training time: {end - start:.2f} seconds\")\n",
        "\n",
        "    # Оценка\n",
        "    y_pred = (model.predict(X_val) > 0.5).astype(int)\n",
        "    bal_acc = balanced_accuracy_score(y_val, y_pred)\n",
        "    logging.info(f\"Balanced accuracy on validation: {bal_acc:.4f}\")\n",
        "    logging.info(\"\\n\" + classification_report(y_val, y_pred))\n",
        "\n",
        "    return model, bal_acc\n"
      ],
      "metadata": {
        "id": "2mlQBGm8AZ7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_save(model, preprocessor, input_json_path, output_json_path):\n",
        "    df = load_and_preprocess(input_json_path)\n",
        "\n",
        "    X_pred = df.drop(columns=['accountId'])\n",
        "    X_pred_proc = preprocessor.transform(X_pred)\n",
        "\n",
        "    probs = model.predict(X_pred_proc).flatten()\n",
        "    threshold = 0.5\n",
        "    results = []\n",
        "    for idx, account_id in enumerate(df['accountId']):\n",
        "        results.append({\n",
        "            \"accountId\": int(account_id),\n",
        "            \"isCommercial\": bool(probs[idx] > threshold),\n",
        "            \"probability\": float(round(probs[idx], 4))\n",
        "        })\n",
        "\n",
        "    with open(output_json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "    logging.info(f\"Predictions saved to {output_json_path}\")\n"
      ],
      "metadata": {
        "id": "GJRSPk7nAeV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузи и подготовь данные обучения\n",
        "df_train = load_and_preprocess('dataset_train.json')\n",
        "\n",
        "X_train, y_train, preprocessor = prepare_train_data(df_train, target_column='isCommercial')\n",
        "\n",
        "# Обучи модель\n",
        "model, bal_acc = train_model(X_train, y_train)\n",
        "\n",
        "# Сохрани модель и препроцессор для повторного использования\n",
        "model.save('keras_model.h5')\n",
        "\n",
        "import joblib\n",
        "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
        "\n",
        "# Предскажем для новых данных\n",
        "predict_and_save(model, preprocessor, 'new_data.json', 'prediction_results.json')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jmxJTpNAgh9",
        "outputId": "a83372cb-976e-4342-ee81-2bb613f96d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144/144 - 3s - 19ms/step - accuracy: 0.5864 - loss: 0.6775 - val_accuracy: 0.6316 - val_loss: 0.6530\n",
            "Epoch 2/100\n",
            "144/144 - 1s - 7ms/step - accuracy: 0.6322 - loss: 0.6449 - val_accuracy: 0.6429 - val_loss: 0.6339\n",
            "Epoch 3/100\n",
            "144/144 - 1s - 7ms/step - accuracy: 0.6413 - loss: 0.6329 - val_accuracy: 0.6429 - val_loss: 0.6396\n",
            "Epoch 4/100\n",
            "144/144 - 1s - 4ms/step - accuracy: 0.6483 - loss: 0.6238 - val_accuracy: 0.6455 - val_loss: 0.6221\n",
            "Epoch 5/100\n",
            "144/144 - 1s - 4ms/step - accuracy: 0.6541 - loss: 0.6194 - val_accuracy: 0.6603 - val_loss: 0.6211\n",
            "Epoch 6/100\n",
            "144/144 - 1s - 4ms/step - accuracy: 0.6485 - loss: 0.6218 - val_accuracy: 0.6568 - val_loss: 0.6259\n",
            "Epoch 7/100\n",
            "144/144 - 1s - 4ms/step - accuracy: 0.6635 - loss: 0.6103 - val_accuracy: 0.6551 - val_loss: 0.6114\n",
            "Epoch 8/100\n",
            "144/144 - 1s - 4ms/step - accuracy: 0.6657 - loss: 0.6102 - val_accuracy: 0.6646 - val_loss: 0.6100\n",
            "Epoch 9/100\n",
            "144/144 - 0s - 3ms/step - accuracy: 0.6752 - loss: 0.5994 - val_accuracy: 0.6646 - val_loss: 0.6074\n",
            "Epoch 10/100\n",
            "144/144 - 0s - 3ms/step - accuracy: 0.6796 - loss: 0.5992 - val_accuracy: 0.6759 - val_loss: 0.6063\n",
            "Epoch 11/100\n",
            "144/144 - 1s - 4ms/step - accuracy: 0.6706 - loss: 0.6008 - val_accuracy: 0.6733 - val_loss: 0.6013\n",
            "Epoch 12/100\n",
            "144/144 - 1s - 4ms/step - accuracy: 0.6852 - loss: 0.5946 - val_accuracy: 0.6794 - val_loss: 0.6029\n",
            "Epoch 13/100\n",
            "144/144 - 0s - 3ms/step - accuracy: 0.6780 - loss: 0.5906 - val_accuracy: 0.6681 - val_loss: 0.6047\n",
            "Epoch 14/100\n",
            "144/144 - 1s - 5ms/step - accuracy: 0.6859 - loss: 0.5869 - val_accuracy: 0.6794 - val_loss: 0.5967\n",
            "Epoch 15/100\n",
            "144/144 - 1s - 4ms/step - accuracy: 0.6841 - loss: 0.5797 - val_accuracy: 0.6785 - val_loss: 0.6018\n",
            "Epoch 16/100\n",
            "144/144 - 1s - 4ms/step - accuracy: 0.6904 - loss: 0.5808 - val_accuracy: 0.6733 - val_loss: 0.5959\n",
            "Epoch 17/100\n",
            "144/144 - 0s - 3ms/step - accuracy: 0.6987 - loss: 0.5790 - val_accuracy: 0.6820 - val_loss: 0.5910\n",
            "Epoch 18/100\n",
            "144/144 - 1s - 5ms/step - accuracy: 0.6937 - loss: 0.5751 - val_accuracy: 0.6759 - val_loss: 0.5923\n",
            "Epoch 19/100\n",
            "144/144 - 1s - 5ms/step - accuracy: 0.6950 - loss: 0.5759 - val_accuracy: 0.6942 - val_loss: 0.5848\n",
            "Epoch 20/100\n",
            "144/144 - 1s - 5ms/step - accuracy: 0.7015 - loss: 0.5707 - val_accuracy: 0.6751 - val_loss: 0.5932\n",
            "Epoch 21/100\n",
            "144/144 - 1s - 5ms/step - accuracy: 0.6943 - loss: 0.5709 - val_accuracy: 0.6968 - val_loss: 0.5879\n",
            "Epoch 22/100\n",
            "144/144 - 1s - 7ms/step - accuracy: 0.6989 - loss: 0.5675 - val_accuracy: 0.6924 - val_loss: 0.5861\n",
            "Epoch 23/100\n",
            "144/144 - 1s - 5ms/step - accuracy: 0.7002 - loss: 0.5618 - val_accuracy: 0.6725 - val_loss: 0.5973\n",
            "Epoch 24/100\n",
            "144/144 - 1s - 4ms/step - accuracy: 0.7089 - loss: 0.5621 - val_accuracy: 0.6794 - val_loss: 0.5889\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
          ]
        }
      ]
    }
  ]
}